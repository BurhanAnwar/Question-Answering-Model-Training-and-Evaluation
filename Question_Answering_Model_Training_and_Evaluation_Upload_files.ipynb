{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -qqq simpletransformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LX-RbeKhJvVh",
        "outputId": "881f5bf3-fbbe-4b40-a0b1-1e0d4ae061bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m315.5/315.5 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m56.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.1/281.1 kB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m401.2/401.2 kB\u001b[0m \u001b[31m48.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m78.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.0/83.0 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from simpletransformers.question_answering import QuestionAnsweringModel\n",
        "from sklearn.model_selection import train_test_split\n",
        "import wandb"
      ],
      "metadata": {
        "id": "zh2fyhKkgia3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"train.csv\")\n",
        "train_df, eval_df = train_test_split(data, test_size=0.25, random_state=42)"
      ],
      "metadata": {
        "id": "G7Mvyj7_gkCf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_configs = {\n",
        "    \"bert\": {\n",
        "        \"model_type\": \"bert\",\n",
        "        \"model_name\": \"bert-base-uncased\",\n",
        "        \"train_batch_size\": 16,\n",
        "        \"eval_batch_size\": 16,\n",
        "        \"num_train_epochs\": 3,\n",
        "        \"learning_rate\": 5e-5,\n",
        "        \"wandb_project\": \"MedQuad_QA_BERT\"\n",
        "    },\n",
        "    \"mobilebert\": {\n",
        "        \"model_type\": \"bert\",\n",
        "        \"model_name\": \"google/mobilebert-uncased\",\n",
        "        \"train_batch_size\": 16,\n",
        "        \"eval_batch_size\": 16,\n",
        "        \"num_train_epochs\": 3,\n",
        "        \"learning_rate\": 5e-5,\n",
        "        \"wandb_project\": \"MedQuad_QA_MobileBERT\"\n",
        "    },\n",
        "    \"roberta\": {\n",
        "        \"model_type\": \"roberta\",\n",
        "        \"model_name\": \"roberta-base\",\n",
        "        \"train_batch_size\": 16,\n",
        "        \"eval_batch_size\": 16,\n",
        "        \"num_train_epochs\": 3,\n",
        "        \"learning_rate\": 5e-5,\n",
        "        \"wandb_project\": \"MedQuad_QA_RoBERTa\"\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "oOBgTfSMgqA0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hyperparameters = [\n",
        "    {\"num_train_epochs\": 3, \"learning_rate\": 5e-5, \"dropout\": 0.3},\n",
        "    {\"num_train_epochs\": 3, \"learning_rate\": 5e-5, \"dropout\": 0.7}\n",
        "]"
      ],
      "metadata": {
        "id": "vCzBmEGOgsPZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vuy-f8u8JK5N"
      },
      "outputs": [],
      "source": [
        "def preprocess_data(df):\n",
        "    examples = []\n",
        "    for idx, row in df.iterrows():\n",
        "        context = row[\"Answer\"]\n",
        "        qas = [{\"question\": row[\"Question\"], \"id\": idx, \"answers\": [{\"text\": row[\"Answer\"], \"answer_start\": 0}]}]\n",
        "        examples.append({\"context\": context, \"qas\": qas})\n",
        "    return examples\n",
        "for model_name, config in model_configs.items():\n",
        "    for hp in hyperparameters:\n",
        "        config.update(hp)\n",
        "        train_examples = preprocess_data(train_df)\n",
        "        eval_examples = preprocess_data(eval_df)\n",
        "        wandb.init(project=config[\"wandb_project\"], config=config)\n",
        "        model = QuestionAnsweringModel(model_type=config[\"model_type\"],\n",
        "                                       model_name=config[\"model_name\"],\n",
        "                                       args=config)\n",
        "        output_dir = f\"{model_name} {hp}\"\n",
        "        model.train_model(train_examples, output_dir=output_dir)\n",
        "        result = model.eval_model(eval_examples)\n",
        "        wandb.log({\"eval_results\": result})"
      ]
    }
  ]
}